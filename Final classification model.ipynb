{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: ## no need of plt.show()\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline ## no need of plt.show()\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re, string, os, sys\n",
    "from datetime import datetime\n",
    "import warnings # To ignore any warnings (Good to have)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# viz\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "# tree viz\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid,KFold, StratifiedKFold\n",
    "#from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, forest, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import average_precision_score,precision_recall_curve\n",
    "from math import sqrt\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import preprocessing # label encoding\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,classification_report,confusion_matrix,auc # auc\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:/case studies/wayfair/data/\" # update this as path where you keep your data files while runnng notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = [\"n/a\", \"na\", \"--\",\"NA\",\"NAN\"] # checking NAs, NANs if present as string in dataframe \n",
    "train_df = pd.read_csv(path+\"df_training_scholarjet.csv\",na_values = missing_values)\n",
    "\n",
    "test_df = pd.read_csv(path+\"df_holdout_scholarjet.csv\",na_values = missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_save = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop([\"Unnamed: 0\",\"cuid\"], axis =1,inplace=True)\n",
    "test_df.drop([\"Unnamed: 0\",\"cuid\"], axis =1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]: \n",
    "    df[\"activeonsite_3days\"] = (df.numvisitone>0) | (df.numvisitthreeone>0) \n",
    "    df[\"activeonsite_7days\"] = (df.numvisitone>0) | (df.numvisitthreeone>0) | (df.numvisitseventhree>0)\n",
    "    df[\"activeonsite_30days\"] = (df.numvisitone>0) | (df.numvisitthreeone>0) | (df.numvisitseventhree>0) |  (df.numvisitthirtyseven>0)\n",
    "    list_name = [\"numorderone\",\"numorderthreeone\",\"numorderseventhree\",\"numorderthirtyseven\"]\n",
    "    list_ord = list_name + [\"numordersixtythirty\",\"numorderyearsixty\"]\n",
    "    df[\"monthly_cycle\"] = (df.loc[:,list_name].fillna(0).sum(axis=1)>0) & (df.numordersixtythirty>0) &(df.numorderyearsixty>0)\n",
    "    df[\"orders_per_month\"] = ((df.loc[:,list_ord].fillna(0).sum(axis=1))/(df.dayssinceenrollment))*30\n",
    "    df[\"ordered_last_month\"] = df.loc[:,list_name].fillna(0).sum(axis=1)>0 # recency of purchase\n",
    "    df[\"ordered_last_3days\"] = (df.numorderone>0) | (df.numorderthreeone>0) \n",
    "    df[\"ordered_last_7days\"] = (df.numorderone>0) | (df.numorderthreeone>0) | (df.numorderseventhree>0)\n",
    "    list_name_email = [\"numemailsone\",\"numemailsthreeone\",\"numemailsseventhree\",\"numemailsthirtyseven\"]\n",
    "    df[\"email_BAM_last_month\"] = df.loc[:,list_name_email].fillna(0).sum(axis=1)>0\n",
    "    df[\"email_BAM_last_3days\"] = (df.numemailsone>0) | (df.numemailsthreeone>0) \n",
    "    df[\"email_BAM_last_7days\"] = (df.numemailsone>0) | (df.numemailsthreeone>0)  | (df.numemailsseventhree>0)\n",
    "    list_name_calls = [\"numcallsone\",\"numcallsthreeone\",\"numcallsseventhree\",\"numcallsthirtyseven\"]\n",
    "    df[\"calls_last_month\"] = df.loc[:,list_name_calls].fillna(0).sum(axis=1)>0\n",
    "    df[\"calls_last_3days\"] = (df.numcallsone>0) | (df.numcallsthreeone>0) \n",
    "    df[\"calls_last_7days\"] = (df.numcallsone>0) | (df.numcallsthreeone>0)  | (df.numcallsseventhree>0)\n",
    "    list_em_call = list_name_email + list_name_calls \n",
    "    df[\"calls&emails_last_month\"] = df.loc[:,list_em_call].fillna(0).sum(axis=1)>0\n",
    "    list_atc = [\"numatcone\",\"numatcthreeone\",\"numatcseventhree\",\"numatcthirtyseven\"]\n",
    "    df[\"atc&no_purchase_last_month\"] = (df.loc[:,list_name].fillna(0).sum(axis=1)==0) & (df.loc[:,list_atc].fillna(0).sum(axis=1)>0)\n",
    "    df[\"atc_last_month\"] = df.loc[:,list_atc].fillna(0).sum(axis=1)>0\n",
    "    df[\"atc_last_3days\"] = (df.numatcone>0) | (df.numatcthreeone>0) \n",
    "    df[\"atc_last_7days\"] = (df.numatcone>0) | (df.numatcthreeone>0)  | (df.numatcseventhree>0)\n",
    "    list_name_sku = [\"numskusviewedone\",\"numskusviewedthreeone\",\"numskusviewedseventhree\",\"numskusviewedthirtyseven\"]\n",
    "    df[\"sku_last_month\"] = df.loc[:,list_name_sku].fillna(0).sum(axis=1)>0\n",
    "    df[\"sku_last_3days\"] = (df.numskusviewedone>0) | (df.numskusviewedthreeone>0) \n",
    "    df[\"sku_last_7days\"] = (df.numskusviewedone>0) | (df.numskusviewedthreeone>0)  | (df.numskusviewedseventhree>0)\n",
    "    list_name_search = [ \"numsearchtermsone\",\"numsearchtermsthreeone\",\"numsearchtermsseventhree\",\"numsearchtermsthirtyseven\"]\n",
    "    df[\"search_last_month\"] = df.loc[:,list_name_search].fillna(0).sum(axis=1)>0\n",
    "    df[\"search_last_3days\"] = (df.numsearchtermsone>0) | (df.numsearchtermsthreeone>0) \n",
    "    df[\"search_last_7days\"] = (df.numsearchtermsone>0) | (df.numsearchtermsthreeone>0)  | (df.numsearchtermsseventhree>0)\n",
    "    list_name_tasks = [\"numtasksfirstintroone\",\"numtasksfirstintrothreeone\",\"numtasksfirstintroseventhree\",\"numtasksfirstintrothirtyseven\"]\n",
    "    df[\"tasks_last_month\"] = df.loc[:,list_name_tasks].fillna(0).sum(axis=1)>0\n",
    "    df[\"tasks_last_3days\"] = (df.numtasksfirstintroone>0) | (df.numtasksfirstintrothreeone>0) \n",
    "    df[\"tasks_last_7days\"] = (df.numtasksfirstintroone>0) | (df.numtasksfirstintrothreeone>0)  | (df.numtasksfirstintroseventhree>0)\n",
    "    list_or_7 = [\"numorderone\",\"numorderthreeone\",\"numorderseventhree\"]\n",
    "    list_act = [\"numskusviewedone\",\"numskusviewedthreeone\",\"numskusviewedseventhree\",\n",
    "            \"numsearchtermsone\",\"numsearchtermsthreeone\",\"numsearchtermsseventhree\"]\n",
    "    df[\"activity&no_purchase_7days\"] = (df.loc[:,list_or_7].fillna(0).sum(axis=1)==0) & (df.loc[:,list_act].fillna(0).sum(axis=1)>0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding is_na features\n",
    "add a {name}_na column which specifies if the data was missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "167\n"
     ]
    }
   ],
   "source": [
    "for d in [train_df, test_df]:  \n",
    "    missing = d.isna().sum()\n",
    "    cols_missing = list(missing[missing > 0].index)\n",
    "    print(len(cols_missing))\n",
    "    for name in cols_missing:\n",
    "        d[name + '_na'] = pd.isnull(d[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]: \n",
    "    df.fillna(value=-100,inplace=True) # rest we replace by a constant value, as missing data has its own meaning # 0 already present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_to_int(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'bool':\n",
    "            df[col] = df[col]*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_to_int(train_df)\n",
    "bool_to_int(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28126, 379), (30375, 376))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean target encoding - Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder_regularized(train, test, cols_encode, target, folds = 5):\n",
    "    \"\"\"\n",
    "    Mean regularized target encoding based on kfold\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=1)\n",
    "    #     set_trace()\n",
    "    test_copy = test.reset_index().copy()\n",
    "    train_copy = train.reset_index().copy()\n",
    "    \n",
    "    for col in cols_encode:      \n",
    "        encoded_column = col + \"_mean_target\"\n",
    "        train_copy[encoded_column] = np.zeros(len(train_copy))\n",
    "        test_copy[encoded_column] = np.zeros(len(test_copy))\n",
    "        \n",
    "        for train_index, val_index in kf.split(train):\n",
    "\n",
    "            mean_target =  train_copy.loc[train_index].groupby(col)[target].mean()\n",
    "\n",
    "            train_copy.loc[val_index,encoded_column] = train_copy.loc[val_index, col].map(mean_target)\n",
    "        \n",
    "        global_mean = train_copy[target].mean()\n",
    "        train_copy[encoded_column].fillna(global_mean, inplace=True)\n",
    "        \n",
    "        # making test encoding using full training data \n",
    "        test_copy[encoded_column] = test_copy[col].map(train_copy.groupby(col)[target].mean())\n",
    "        test_copy[encoded_column].fillna(global_mean, inplace=True)\n",
    "            \n",
    "    return train_copy, test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['roll_up',\n",
       " 'currentstatus',\n",
       " 'companytypegroup',\n",
       " 'team',\n",
       " 'customersource',\n",
       " 'accrole',\n",
       " 'num_employees',\n",
       " 'num_purchases_year',\n",
       " 'cost_purchases_year',\n",
       " 'enrollmentmethod']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = list(train_df.select_dtypes(include='object').columns) # 10 columns\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = target_encoder_regularized(train_df, test_df, cat_columns,target='convert_30', folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_v2.loc[df_train_v2.roll_up==\"Unmanaged\",[\"roll_up\",\"roll_up_mean_target\"]]\n",
    "#df_val_v2.loc[:,[\"roll_up\",\"roll_up_mean_target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df_train, df_test, cols):\n",
    "    \"\"\"\n",
    "    Drop a list of columns from both train df and test df\n",
    "    \"\"\"\n",
    "    \n",
    "    df_train.drop(cols, inplace=True, axis=1)\n",
    "    df_test.drop(cols, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns(df_train, df_test, cat_columns+[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['orders_per_month'].replace(np.inf,-200,inplace=True)\n",
    "df_test['orders_per_month'].replace(np.inf,-200,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30375, 376), (28126, 379))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape, df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.copy().drop(['convert_30','revenue_30'], axis=1) # removing target variables\n",
    "y = df_train.copy()['convert_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28126, 377), (28126,), (30375, 376))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_columns = ['numreturn',\n",
    " 'numideaboardsixtythirty',\n",
    " 'sumrevthreeone',\n",
    " 'search_last_month',\n",
    " 'sumrevseventhree',\n",
    " 'avgpricesixtythirty_na',\n",
    " 'numwims',\n",
    " 'numcallsseventhree',\n",
    " 'numtasksfirstintroseventhree',\n",
    " 'numemailsseventhree',\n",
    " 'percentresolved',\n",
    " 'numcallsthreeone',\n",
    " 'numorderthirtyseven',\n",
    " 'numemailssixtythirty',\n",
    " 'numcallssixtythirty',\n",
    " 'percdirtythirty',\n",
    " 'numinf',\n",
    " 'numsearchtermsthreeone',\n",
    " 'numordersixtythirty',\n",
    " 'percemailclickedseventhree',\n",
    " 'avgquoteprice',\n",
    " 'numother',\n",
    " 'percsecondsinbound',\n",
    " 'numtasksfirstintrothirtyseven',\n",
    " 'percemailclickedthreeone',\n",
    " 'numcallsthirtyseven',\n",
    " 'numtasksfirstintroyearsixty',\n",
    " 'numloggedinthreeone',\n",
    " 'numsearchtermsseventhree',\n",
    " 'numvisitthreeone',\n",
    " 'totalcalldurationseventhree',\n",
    " 'sumrevsixtythirty',\n",
    " 'numatcthirtyseven',\n",
    " 'percemailopenedone',\n",
    " 'numvisitone',\n",
    " 'percemailopenedthreeone',\n",
    " 'avgpriceone',\n",
    " 'numsearchtermssixtythirty',\n",
    " 'sumrevthirtyseven',\n",
    " 'numcallsyearsixty',\n",
    " 'numemaillist',\n",
    " 'numsearchtermsone',\n",
    " 'sumrevyearsixty',\n",
    " 'numemailsyearsixty',\n",
    " 'numloggedinseventhree',\n",
    " 'numorderyearsixty',\n",
    " 'numsecondsonsiteone',\n",
    " 'totalcalldurationsixtythirty',\n",
    " 'numideaboardyearsixty',\n",
    " 'numideaboardthirtyseven',\n",
    " 'numatcsixtythirty',\n",
    " 'numselforder',\n",
    " 'numsecondsonsitethreeone',\n",
    " 'numskusviewedseventhree',\n",
    " 'aov',\n",
    " 'numskusviewedthreeone',\n",
    " 'numtotalpageviewsone',\n",
    " 'avgpriceseventhree_na',\n",
    " 'numloggedinsixtythirty',\n",
    " 'totalcalldurationthirtyseven',\n",
    " 'avgpriceone_na',\n",
    " 'dayssincelastord',\n",
    " 'numatcyearsixty',\n",
    " 'numskusviewedone',\n",
    " 'percemailopenedseventhree',\n",
    " 'numskusviewedsixtythirty',\n",
    " 'avgpriceseventhree',\n",
    " 'totalrev',\n",
    " 'activeonsite_7days',\n",
    " 'percemailclickedsixtythirty',\n",
    " 'numsearchtermsthirtyseven',\n",
    " 'totalcalldurationyearsixty',\n",
    " 'percemailclickedthirtyseven',\n",
    " 'companytypegroup_mean_target',\n",
    " 'team_mean_target',\n",
    " 'atc_last_month',\n",
    " 'numvisitseventhree',\n",
    " 'numvisitthirtyseven',\n",
    " 'numloggedinthirtyseven',\n",
    " 'currentapplicability',\n",
    " 'percemailclickedyearsixty',\n",
    " 'accrole_mean_target',\n",
    " 'percemailopenedsixtythirty',\n",
    " 'numsecondsonsitesixtythirty',\n",
    " 'orders_per_month',\n",
    " 'dayssincelastvisit',\n",
    " 'numvisitsixtythirty',\n",
    " 'percemailopenedyearsixty',\n",
    " 'numsearchtermsyearsixty',\n",
    " 'cost_purchases_year_mean_target',\n",
    " 'numtotalpageviewssixtythirty',\n",
    " 'num_purchases_year_mean_target',\n",
    " 'avgatcprice',\n",
    " 'roll_up_mean_target',\n",
    " 'numloggedinyearsixty',\n",
    " 'avgpricethirtyseven',\n",
    " 'numvisityearsixty',\n",
    " 'avgpricesixtythirty',\n",
    " 'currentstatus_mean_target',\n",
    " 'numsecondsonsiteyearsixty',\n",
    " 'num_employees_mean_target',\n",
    " 'sumatcprice',\n",
    " 'percemailopenedthirtyseven',\n",
    " 'avgpricethreeone',\n",
    " 'numtotalpageviewsthreeone',\n",
    " 'numtotalpageviewsyearsixty',\n",
    " 'numvisittotal',\n",
    " 'numskusviewedyearsixty',\n",
    " 'enrollmentmethod_mean_target',\n",
    " 'customersource_mean_target',\n",
    " 'numsecondsonsitethirtyseven',\n",
    " 'sku_last_3days',\n",
    " 'dayssinceenrollment',\n",
    " 'avgprice',\n",
    " 'numskusviewedthirtyseven',\n",
    " 'avgpriceyearsixty',\n",
    " 'numsecondsonsiteseventhree',\n",
    " 'numtotalpageviewsseventhree',\n",
    " 'numtotalpageviewsthirtyseven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[imp_columns]\n",
    "df_test = df_test[imp_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "m = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                  colsample_bytree=0.4, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "                  max_depth=4, min_child_weight=3, missing=-999, n_estimators=100,\n",
    "                  n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
    "                  reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337, silent=0,\n",
    "                  subsample=0.75)\n",
    "    \n",
    "\n",
    "m.fit(X, y)  \n",
    "prediction_score = m.predict_proba(df_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prediction\"] = prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"class_prediction_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_1 = df_train.loc[df_train.revenue_30>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_1.revenue_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.copy().drop(['convert_30','revenue_30'], axis=1) # removing target variables\n",
    "y = df_train.copy()['revenue_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 34986.6899, 75.03899719476578)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(), y.max(),y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28126, 377), (28126,), (30375, 120))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_columns = ['numreturn',\n",
    " 'numideaboardsixtythirty',\n",
    " 'sumrevthreeone',\n",
    " 'search_last_month',\n",
    " 'sumrevseventhree',\n",
    " 'avgpricesixtythirty_na',\n",
    " 'numwims',\n",
    " 'numcallsseventhree',\n",
    " 'numtasksfirstintroseventhree',\n",
    " 'numemailsseventhree',\n",
    " 'percentresolved',\n",
    " 'numcallsthreeone',\n",
    " 'numorderthirtyseven',\n",
    " 'numemailssixtythirty',\n",
    " 'numcallssixtythirty',\n",
    " 'percdirtythirty',\n",
    " 'numinf',\n",
    " 'numsearchtermsthreeone',\n",
    " 'numordersixtythirty',\n",
    " 'percemailclickedseventhree',\n",
    " 'avgquoteprice',\n",
    " 'numother',\n",
    " 'percsecondsinbound',\n",
    " 'numtasksfirstintrothirtyseven',\n",
    " 'percemailclickedthreeone',\n",
    " 'numcallsthirtyseven',\n",
    " 'numtasksfirstintroyearsixty',\n",
    " 'numloggedinthreeone',\n",
    " 'numsearchtermsseventhree',\n",
    " 'numvisitthreeone',\n",
    " 'totalcalldurationseventhree',\n",
    " 'sumrevsixtythirty',\n",
    " 'numatcthirtyseven',\n",
    " 'percemailopenedone',\n",
    " 'numvisitone',\n",
    " 'percemailopenedthreeone',\n",
    " 'avgpriceone',\n",
    " 'numsearchtermssixtythirty',\n",
    " 'sumrevthirtyseven',\n",
    " 'numcallsyearsixty',\n",
    " 'numemaillist',\n",
    " 'numsearchtermsone',\n",
    " 'sumrevyearsixty',\n",
    " 'numemailsyearsixty',\n",
    " 'numloggedinseventhree',\n",
    " 'numorderyearsixty',\n",
    " 'numsecondsonsiteone',\n",
    " 'totalcalldurationsixtythirty',\n",
    " 'numideaboardyearsixty',\n",
    " 'numideaboardthirtyseven',\n",
    " 'numatcsixtythirty',\n",
    " 'numselforder',\n",
    " 'numsecondsonsitethreeone',\n",
    " 'numskusviewedseventhree',\n",
    " 'aov',\n",
    " 'numskusviewedthreeone',\n",
    " 'numtotalpageviewsone',\n",
    " 'avgpriceseventhree_na',\n",
    " 'numloggedinsixtythirty',\n",
    " 'totalcalldurationthirtyseven',\n",
    " 'avgpriceone_na',\n",
    " 'dayssincelastord',\n",
    " 'numatcyearsixty',\n",
    " 'numskusviewedone',\n",
    " 'percemailopenedseventhree',\n",
    " 'numskusviewedsixtythirty',\n",
    " 'avgpriceseventhree',\n",
    " 'totalrev',\n",
    " 'activeonsite_7days',\n",
    " 'percemailclickedsixtythirty',\n",
    " 'numsearchtermsthirtyseven',\n",
    " 'totalcalldurationyearsixty',\n",
    " 'percemailclickedthirtyseven',\n",
    " 'companytypegroup_mean_target',\n",
    " 'team_mean_target',\n",
    " 'atc_last_month',\n",
    " 'numvisitseventhree',\n",
    " 'numvisitthirtyseven',\n",
    " 'numloggedinthirtyseven',\n",
    " 'currentapplicability',\n",
    " 'percemailclickedyearsixty',\n",
    " 'accrole_mean_target',\n",
    " 'percemailopenedsixtythirty',\n",
    " 'numsecondsonsitesixtythirty',\n",
    " 'orders_per_month',\n",
    " 'dayssincelastvisit',\n",
    " 'numvisitsixtythirty',\n",
    " 'percemailopenedyearsixty',\n",
    " 'numsearchtermsyearsixty',\n",
    " 'cost_purchases_year_mean_target',\n",
    " 'numtotalpageviewssixtythirty',\n",
    " 'num_purchases_year_mean_target',\n",
    " 'avgatcprice',\n",
    " 'roll_up_mean_target',\n",
    " 'numloggedinyearsixty',\n",
    " 'avgpricethirtyseven',\n",
    " 'numvisityearsixty',\n",
    " 'avgpricesixtythirty',\n",
    " 'currentstatus_mean_target',\n",
    " 'numsecondsonsiteyearsixty',\n",
    " 'num_employees_mean_target',\n",
    " 'sumatcprice',\n",
    " 'percemailopenedthirtyseven',\n",
    " 'avgpricethreeone',\n",
    " 'numtotalpageviewsthreeone',\n",
    " 'numtotalpageviewsyearsixty',\n",
    " 'numvisittotal',\n",
    " 'numskusviewedyearsixty',\n",
    " 'enrollmentmethod_mean_target',\n",
    " 'customersource_mean_target',\n",
    " 'numsecondsonsitethirtyseven',\n",
    " 'sku_last_3days',\n",
    " 'dayssinceenrollment',\n",
    " 'avgprice',\n",
    " 'numskusviewedthirtyseven',\n",
    " 'avgpriceyearsixty',\n",
    " 'numsecondsonsiteseventhree',\n",
    " 'numtotalpageviewsseventhree',\n",
    " 'numtotalpageviewsthirtyseven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[imp_columns]\n",
    "df_test = df_test[imp_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28126, 119), (28126,), (30375, 119))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "m = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                  colsample_bytree=0.4, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "                  max_depth=4, min_child_weight=3, missing=-999, n_estimators=100,\n",
    "                  n_jobs=1, nthread=4, random_state=0,\n",
    "                  reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1337, silent=0,\n",
    "                  subsample=0.75)\n",
    "    \n",
    "\n",
    "m.fit(X, y)  \n",
    "prediction_score = m.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = XGBRegressor()\n",
    "    \n",
    "m.fit(X, y)  \n",
    "prediction_score = m.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-171.66632, 10799.494, 65.44772)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_score.min(), prediction_score.max(),prediction_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"rev_prediction\"] = prediction_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"reg_prediction_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
